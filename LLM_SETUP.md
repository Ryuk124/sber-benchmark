# ü§ñ LLM Integration Guide

–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å —Ä–∞–∑–Ω—ã–º–∏ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏. –í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ —É–¥–æ–±–Ω—ã–π –¥–ª—è –≤–∞—Å.

## üöÄ –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä

### –í–∞—Ä–∏–∞–Ω—Ç 1: OpenAI GPT (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)
**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –ª–µ–≥–∫–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è, –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π trial  
**–ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ**: –î–µ—à–µ–≤–ª–µ –≤—Å–µ–≥–æ

```bash
pip install openai==1.3.0
```

**–®–∞–≥ 1**: –ü–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á –Ω–∞ https://platform.openai.com/api-keys

**–®–∞–≥ 2**: –î–æ–±–∞–≤–∏—Ç—å –≤ `.env`:
```
OPENAI_API_KEY=sk-proj-your-key-here
```

**–®–∞–≥ 3**: –ì–æ—Ç–æ–≤–æ! –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPT-3.5-turbo

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: Anthropic Claude
**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å

```bash
pip install anthropic==0.7.0
```

**–®–∞–≥ 1**: –ü–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á –Ω–∞ https://www.anthropic.com/

**–®–∞–≥ 2**: –î–æ–±–∞–≤–∏—Ç—å –≤ `.env`:
```
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

**–®–∞–≥ 3**: –û–±–Ω–æ–≤–∏—Ç—å `llm_service.py` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Claude

---

### –í–∞—Ä–∏–∞–Ω—Ç 3: –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (Ollama, LLaMA2)
**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –ü–æ–ª–Ω–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å, –±–µ–∑ –ª–∏–º–∏—Ç–æ–≤

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama**:
```bash
# macOS / Linux
curl -fsSL https://ollama.ai/install.sh | sh

# –ò–ª–∏ —Å–∫–∞—á–∞—Ç—å —Å https://ollama.ai
```

**–ó–∞–ø—É—Å—Ç–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å**:
```bash
ollama run llama2
# –∏–ª–∏ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å: mistral, neural-chat, –∏ —Ç.–¥.
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Å–∏—Å—Ç–µ–º—É**:
```python
# llm_service.py - –¥–æ–±–∞–≤–∏—Ç—å
import requests

def _analyze_with_ollama(self, text, competitor, product, criterion):
    response = requests.post(
        'http://localhost:11434/api/generate',
        json={
            'model': 'llama2',
            'prompt': f'Analyze: {text}',
            'stream': False
        }
    )
    return response.json()
```

---

## üìã –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É

### OpenAI GPT

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
pip install openai==1.3.0
```

**–ú–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã**:
- `gpt-3.5-turbo` - –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- `gpt-4` - –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –¥–æ—Ä–æ–∂–µ
- `gpt-4-turbo` - –±—ã—Å—Ç—Ä—ã–π GPT-4

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è**:
```python
from openai import OpenAI

client = OpenAI(api_key="sk-...")

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∞–Ω–∫–∞–º"},
        {"role": "user", "content": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç"}
    ]
)

print(response.choices[0].message.content)
```

**–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π trial**: $5 –Ω–∞ 3 –º–µ—Å—è—Ü–∞  
**–¶–µ–Ω—ã**: $0.0005-$0.03 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤

**–°—Å—ã–ª–∫–∞**: https://platform.openai.com/

---

### Anthropic Claude

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
pip install anthropic==0.7.0
```

**–ú–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã**:
- `claude-3-opus` - –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- `claude-3-sonnet` - —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å
- `claude-3-haiku` - –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è**:
```python
import anthropic

client = anthropic.Anthropic(api_key="sk-ant-...")

message = client.messages.create(
    model="claude-3-sonnet-20240229",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç"}
    ]
)

print(message.content[0].text)
```

**–ü—Ä–æ–±–Ω—ã–π –ø–µ—Ä–∏–æ–¥**: –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –ø–ª–∞–Ω–∞  
**–¶–µ–Ω—ã**: $0.003-$0.03 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤

**–°—Å—ã–ª–∫–∞**: https://www.anthropic.com/

---

### Ollama (–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ macOS**:
```bash
brew install ollama
# –∏–ª–∏ —Å–∫–∞—á–∞—Ç—å —Å https://ollama.ai
```

**–ó–∞–ø—É—Å–∫**:
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä (—Å–ª—É—à–∞–µ—Ç –Ω–∞ localhost:11434)
ollama serve

# –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å
ollama pull llama2
ollama pull mistral
ollama pull neural-chat
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**:
```python
import requests

def analyze_with_ollama(text):
    response = requests.post(
        'http://localhost:11434/api/generate',
        json={
            'model': 'llama2',
            'prompt': text,
            'stream': False
        },
        timeout=60
    )
    return response.json()['response']
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**: 8+ GB RAM, 20+ GB –¥–∏—Å–∫–∞  
**–¶–µ–Ω–∞**: –ë–µ—Å–ø–ª–∞—Ç–Ω–æ  
**–°–∫–æ—Ä–æ—Å—Ç—å**: –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –ü–ö

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏**:
- llama2 (7B) - —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- mistral (7B) - –±—ã—Å—Ç—Ä–æ
- neural-chat (13B) - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è
- –∏ –º–Ω–æ–≥–∏–µ –¥—Ä—É–≥–∏–µ

**–°—Å—ã–ª–∫–∞**: https://ollama.ai/

---

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ —Å–∏—Å—Ç–µ–º–µ

### –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ `llm_service.py`:

```python
def _run_llm_analysis(self, text, competitor, product, criterion):
    # 1. –ü—Ä–æ–±—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenAI –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω API –∫–ª—é—á
    # 2. Fallback –Ω–∞ mock –∞–Ω–∞–ª–∏–∑
    
    # –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥—Ä—É–≥–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:
    # –∞) –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞–∫–µ—Ç: pip install openai/anthropic/ollama
    # –±) –î–æ–±–∞–≤–∏—Ç—å env –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é: OPENAI_API_KEY=...
    # –≤) –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

| –ö—Ä–∏—Ç–µ—Ä–∏–π | OpenAI | Claude | Ollama |
|----------|--------|--------|--------|
| –ö–∞—á–µ—Å—Ç–≤–æ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| –°–∫–æ—Ä–æ—Å—Ç—å | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| –¶–µ–Ω–∞ | üí∞üí∞ | üí∞üí∞üí∞ | üí∞ (–±–µ—Å–ø–ª–∞—Ç–Ω–æ) |
| –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å | ‚ùå | ‚úÖ‚úÖ | ‚úÖ‚úÖ‚úÖ |
| –ü—Ä–æ—Å—Ç–æ—Ç–∞ | ‚úÖ‚úÖ‚úÖ | ‚úÖ‚úÖ | ‚ö†Ô∏è |
| –õ—É—á—à–µ –¥–ª—è | –ü—Ä–æ–¥–∞–∫—à–µ–Ω–∞ | –ö–æ–Ω—Ñ–∏–¥. | –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ |

---

## üöÄ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö:
1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **OpenAI GPT-3.5-turbo**
2. –í–∑—è—Ç—å –ø—Ä–æ–±–Ω—ã–π $5 trial
3. –õ–µ–≥–∫–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è, –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:
1. **OpenAI GPT-3.5-turbo** –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ (–¥–µ—à–µ–≤–æ, –±—ã—Å—Ç—Ä–æ)
2. **GPT-4** –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ (–¥–æ—Ä–æ–∂–µ, –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
3. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Ä–∞—Å—Ö–æ–¥—ã —á–µ—Ä–µ–∑ https://platform.openai.com/account/usage

### –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏:
1. **Ollama + LLaMA2** (–∏–ª–∏ Mistral)
2. –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–æ
3. –ù–µ —Ç—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞

---

## üí° –ü—Ä–∏–º–µ—Ä—ã use cases

### –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø):
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ mock –∞–Ω–∞–ª–∏–∑ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
# –ù–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞
# –•–æ—Ä–æ—à–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
```

### –î–ª—è –±–æ–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã:
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å OpenAI
pip install openai

# –ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á: https://platform.openai.com/api-keys
# –î–æ–±–∞–≤–∏—Ç—å –≤ .env: OPENAI_API_KEY=sk-...
# –ì–æ—Ç–æ–≤–æ!
```

### –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama
brew install ollama
ollama pull llama2
ollama serve

# –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç localhost:11434
```

---

## üîå –ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞–∫–µ—Ç:
   ```bash
   pip install new-llm-package
   ```

2. –î–æ–±–∞–≤–∏—Ç—å env –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –≤ `.env`

3. –û–±–Ω–æ–≤–∏—Ç—å `_run_llm_analysis()` –≤ `llm_service.py`:
   ```python
   def _run_llm_analysis(self, ...):
       if os.getenv('NEW_LLM_KEY'):
           return self._analyze_with_new_llm(...)
       # ... –¥—Ä—É–≥–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
       return self._analyze_with_mock(...)
   ```

4. –°–æ–∑–¥–∞—Ç—å –º–µ—Ç–æ–¥:
   ```python
   def _analyze_with_new_llm(self, text, ...):
       # –í–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
       pass
   ```

---

## üìû –ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã

**Q: –ö–∞–∫–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≤—ã–±—Ä–∞—Ç—å?**  
A: –ù–∞—á–Ω–∏—Ç–µ —Å OpenAI GPT-3.5-turbo. –õ—É—á—à–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞.

**Q: –ë—É–¥–µ—Ç –ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ API –∫–ª—é—á–∞?**  
A: –î–∞, —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç mock-–∞–Ω–∞–ª–∏–∑ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.

**Q: –°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å?**  
A: OpenAI GPT-3.5-turbo —Å—Ç–æ–∏—Ç ~$0.0005 –∑–∞ –∞–Ω–∞–ª–∏–∑ (–æ—á–µ–Ω—å –¥–µ—à–µ–≤–æ).

**Q: –ö–∞–∫–∞—è –º–æ–¥–µ–ª—å –ª—É—á—à–µ?**  
A: GPT-4 –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ–º, –Ω–æ –¥–æ—Ä–æ–∂–µ. GPT-3.5-turbo —Ö–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å.

**Q: –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å?**  
A: –î–∞, Ollama –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å LLaMA2 –ø–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–æ.

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- üîë OpenAI API Keys: https://platform.openai.com/api-keys
- üìñ OpenAI Docs: https://platform.openai.com/docs
- ü§ñ Anthropic Claude: https://www.anthropic.com/
- ü¶ô Ollama: https://ollama.ai/
- üí¨ OpenAI Models: https://platform.openai.com/docs/models

---

**–ù–∞—á–Ω–∏—Ç–µ —Å OpenAI GPT-3.5-turbo - —ç—Ç–æ –ø—Ä–æ—â–µ –≤—Å–µ–≥–æ! üöÄ**
